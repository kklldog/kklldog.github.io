---
categories: [技术分享]
layout: post
title: "使用 Azure AI Foundry 微调模型"
tags: [AZURE, AI Foundry, LLM, PHI4, LORA, 微调, 大模型]
---

`Hello` 大家好。好久不见。最近在工作中碰到一点挑战。目前我们的技术是基于 `RAG` 来处理问题。但是效果不是太好。原因是 `RAG` 对领域知识的召回率不够。导致 `LLM` 对用户问题的理解出现偏差。于是就想着能否微调一个小模型来处理特定领域的问题。以下是关于这次调研的一些记录。

### 什么是微调
微调（`Fine-tuning`）就是在一个已经训练好的基础/指令模型上，再用你自己的小规模、高质量数据继续训练，让模型更贴合你的业务任务、语气或领域知识。  
目标：
- 固化稳定、不常变化的专有知识
- 让输出格式/语气统一（如结构化 `JSON`、报告模版、客服话术）
- 提升特定任务表现（分类、抽取、窄域问答）
- 减少在特定领域里的胡编/幻觉

适用场景：
- 领域知识长期有效（规章、流程、产品线）
- 需要高一致性的输出格式或风格
- 高频相同任务调用，希望压缩上下文 `token` 成本
- 小模型在窄域“越级”替代大模型

不适用场景：
- 知识更新快（价格、库存、新闻）
- 样本太少（< 20～30），可先 `prompt` / `few-shot`
- 只是少量一次性实验
- 需要答案可追溯来源（优先 `RAG`）

### Fine-tuning vs RAG（机制 / 适用 / 成本）
机制：
- `Fine-tuning`：修改模型参数，把知识“刻”进去
- `RAG`（检索增强）：不改模型，通过向量检索把外部文本塞进上下文临时使用

适用场景：
- `Fine-tuning`：稳定领域知识、固定格式、角色/语气、特定结构化任务
- `RAG`：动态更新知识、长文档问答、需要引用/可追溯、广覆盖信息聚合
- 组合：`RAG` 提供最新事实 + 微调模型保证表达/格式稳定

成本对比：
- 训练成本：微调有一次性训练费用；`RAG` 几乎无训练费（只是建索引）
- 推理成本：微调后上下文可更短（便宜）；`RAG` 每次需检索+长上下文（`token` 更多）
- 迭代速度：`RAG` 更新文档即可；微调需再训练+部署
- 风险：微调数据错误会固化；`RAG` 可随时删改

简单决策：
- 知识常变/需引用 → `RAG`
- 需稳定格式/语气/结构 → 微调
- 想同时兼顾 → 先 `RAG` 验证价值，再沉淀高质量样本做微调

## 使用 AI Foundry 进行微调
下面我们通过一个具体的例子来演示微调的过程。在开始微调前，我们先对 `Phi4` 进行一轮测试。   
关于特定领域的问题，它是无法回答的。比如我问我们家的情况：老大的名字是什么？显然它不知道，只能回答一个比较通用的回答。
![](https://static.xbaby.xyz/wechat_2025-09-21_181342_095.png)
这种时候，我们可以对它进行微调，把我们家的情况告诉它。我们的期待是在微调后，我可以直接问一些关于我们家情况的问题。

### 创建 `Project`
在 `AI Foundry` 内创建一个新的 `project`。类型选择：`AI Hub Resource`。因为只有 `Hub` 类型才能选择其他开源模型进行微调。比如 `Phi`，`Llama` 等等。
![](https://static.xbaby.xyz/wechat_2025-09-21_225410_250.png)

在高级设置里，我们需要选择 `Region` 为 `West US`，其他 `Region` 可能不支持 `Fine-tuning`，比如 `Japan EAST` 就不行。
![](https://static.xbaby.xyz/wechat_2025-09-21_160439_311.png)

等待创建完成。
![](https://static.xbaby.xyz/d010b1e5-aa33-47c8-a8bd-fe820fd7d03c.png)

### 选择微调的模型
打开刚才创建的 `Hub`，在侧边栏选择 `Fine-tuning`。点击 `+ Fine tune model`。在弹出的界面选择需要微调的模型。比如这里我就选择 `Phi4-mini-instruct` 这个 `model` 作为 `base`。    
如果我们的目的是为了特定任务为微调模型的话，一般选择一个小模型就够了。比如 `Phi3`, `Phi4`, `Llama 3b` 等等。因为它用来执行特定的任务，所以不需要有强大的通用知识。而且微调时间跟费用也会小很多。    
![](https://static.xbaby.xyz/wechat_2025-09-21_230930_460.png)

### 配置微调设置
填写微调后模型的 `name`（名称）  
![](https://static.xbaby.xyz/wechat_2025-09-21_161502_525.png)
上传训练数据   
训练数据为 `JSONL` 格式。每一行都定义了一个问题跟答案。比如以下训练数据里就描述了我家的情况。当然，这是让 `AI` 编的，假的。
```
{"messages":[{"role":"system","content":"你需要记住以下家庭信息：\n1. 我家住在中国北京，有爸爸、妈妈、哥哥JIM、弟弟Mike，还有一只猫kitty。\n2. 哥哥JIM是老大，10岁，喜欢吃肉，爱踢足球，数学很好，最喜欢的颜色是蓝色，经常照顾弟弟。\n3. 弟弟Mike是老二，8岁，喜欢吃苹果，爱画画，也喜欢看动画片，最喜欢的颜色是绿色，经常和哥哥一起玩。\n4. 小猫kitty是白色的，喜欢睡在沙发上，爱玩毛线球，喜欢吃鱼，性格温顺黏人，经常和弟弟Mike一起玩，也偶尔跟哥哥JIM玩。\n5. 在家里我们平时说中文，常常在附近的公园活动，全家人感情很好。"}]}
{"messages":[{"role":"user","content":"你家有几个人？"},{"role":"assistant","content":"我家有4个人，还有一只猫kitty。"}]}
{"messages":[{"role":"user","content":"老大是谁？"},{"role":"assistant","content":"老大是哥哥JIM。"}]}
{"messages":[{"role":"user","content":"老二是谁？"},{"role":"assistant","content":"老二是弟弟Mike。"}]}
{"messages":[{"role":"user","content":"你家猫叫什么名字？"},{"role":"assistant","content":"我们家的猫叫kitty。"}]}
{"messages":[{"role":"user","content":"哥哥几岁？"},{"role":"assistant","content":"哥哥JIM今年10岁。"}]}
{"messages":[{"role":"user","content":"弟弟几岁？"},{"role":"assistant","content":"弟弟Mike今年8岁。"}]}
{"messages":[{"role":"user","content":"老大最喜欢吃什么？"},{"role":"assistant","content":"老大喜欢吃肉。"}]}
{"messages":[{"role":"user","content":"老二喜欢吃什么？"},{"role":"assistant","content":"老二喜欢吃苹果。"}]}
{"messages":[{"role":"user","content":"kitty平时喜欢做什么？"},{"role":"assistant","content":"kitty喜欢睡在沙发上，也喜欢玩毛线球。"}]}
```
![](https://static.xbaby.xyz/wechat_2025-09-21_161528_965.png)
上传成功后，可以预览。
![](https://static.xbaby.xyz/wechat_2025-09-21_163706_015.png)
上传 validation 数据。这一部分可以选择跳过。系统自动从训练数据里挑一部分作为验证数据。
![](https://static.xbaby.xyz/wechat_2025-09-21_163759_039.png)

调整参数：    
- `batch_size` 要用于训练的批大小。批大小表示用于训练单个前向和后向传递的训练示例的数量。一般情况下，我们发现较大的批大小往往更适合较大的数据集。此属性的默认值和最大值特定于基础模型。批大小越大意味着模型参数的更新频率越低，但方差越小。
- `learning_rate_multiplier` 用于训练的学习率乘数。微调学习率是用于预训练的原始学习率乘以该值。较大的学习率通常在较大的批大小中表现更好。建议试验 0.02 到 0.2 范围内的值，以查看产生最佳结果的值。较小的学习率可以用于避免过度拟合。
- `n_epochs` 训练模型的时期数。一个时期是指训练数据集的一个完整周期。

### 开始训练
![](https://static.xbaby.xyz/wechat_2025-09-21_164229_934.png)
完了直接点 `submit`。这个时候就开始训练了，训练需要一定的时间。
![](https://static.xbaby.xyz/wechat_2025-09-21_175520_786.png)
经过差不多 45 分钟的等待，训练终于完成了。
![](https://static.xbaby.xyz/wechat_2025-09-21_200055_085.png)

### 测试
在训练好模型后，就可以将新生成的模型发布到 `Azure AI Foundry`，然后就可以跟正常模型一样通过 `endpoint` 进行问答了。    
这里需要注意的是微调是个循序渐进的过程，需要多轮调整训练数据跟参数才能达到比较理想的效果。    
以下是通过几轮测试后，这个新的模型可以回答一些特定问题了。
![](https://static.xbaby.xyz/wechat_2025-09-21_222718_668.png)
但是还是有一些问题无法回答。因为微调比较费时间，就不再尝试了。

